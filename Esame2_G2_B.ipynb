{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTNb0TbP5vxU"
   },
   "source": [
    "Si prega di compilare il modulo (le tue informazioni)\n",
    "**Please fill in the form (your information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fOjglws50kr"
   },
   "outputs": [],
   "source": [
    "#Codice: Esame2-G2-B\n",
    "\n",
    "\n",
    "#Nome:\n",
    "\n",
    "#Cognome:\n",
    "\n",
    "#Matricola:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ls0H_cw37osc"
   },
   "source": [
    "**Domanda1**: Considera il dataset “digits” di Sklearn e classifica le cifre scritte a mano utilizzando un classificatore Random Forest. Utilizza la convalida incrociata a 5 fold e stampa i risultati medi di accuratezza. Utilizza il 70% dei dati per l’addestramento. Predici le etichette sul set di test, calcola e traccia la matrice di confusione. Traccia l’importanza delle caratteristiche dal modello Random Forest per visualizzare quali caratteristiche sono più significative per la classificazione (10 caratteristiche più importanti). Stampa anche i nomi delle dieci caratteristiche più significative. (10 punti)\n",
    "============================================================================================================\n",
    "**Question1:** Consider the \"digits\" dataset from Sklearn and classify the handwritten digits using a Random Forest classifier. Use 5-fold cross-validation and print the average accuracy results. Use 70% of the data for training. Predict the labels on the test set, compute, and plot the confusion matrix. Plot the feature importance from the Random Forest model to visualize which features are most significant for the classification (Top 10 most important features). Also print the names of the top 10 most significant features. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "\n",
    "\n",
    "# Load the  dataset\n",
    "digits = ?\n",
    "# define data and label\n",
    "X = ?\n",
    "y = ?\n",
    "\n",
    "# Split the dataset into training and text\n",
    "X_train, X_test, y_train, y_test = \n",
    "\n",
    "# Define Classifier\n",
    "rf_clf = ?\n",
    "\n",
    "# Perform Cross Validation \n",
    "cv_scores = ?\n",
    "#print score\n",
    "\n",
    "\n",
    "# Train the model \n",
    "rf_clf.?\n",
    "\n",
    "# Predict the labels \n",
    "y_pred = rf_clf.?\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = ?\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp = ?\n",
    "disp.?(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot feature importance \n",
    "importances = rf_clf.?\n",
    "indices = np.argsort(importances)[::-1][?]\n",
    "# Create feature names as \"pixel_0\", \"pixel_1\", ..., \"pixel_63\"\n",
    "feature_names = [f'pixel_{i}' for i in range(X.shape[1])]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Top 10 Feature Importances\")\n",
    "plt.bar(?, ?, align=\"center\")\n",
    "plt.xticks(range(10), [feature_names[i] for i in indices], rotation=90)\n",
    "plt.xlim([-1, 10])\n",
    "plt.show()\n",
    "\n",
    "# Print the names of the ten most important features\n",
    "?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgrWjno16jFS"
   },
   "source": [
    "**Domanda2**: Considera il dataset “make_circles” di Sklearn. Esegui il clustering K-Means (K=2 cluster). Per generare il dataset, utilizza 300 campioni, un fattore di 0.5 e aggiungi rumore con un parametro noise=0.1. Introduci valori mancanti casuali nel 10% del dataset, quindi imputa questi valori mancanti utilizzando il metodo di imputazione della mediana. Esegui il clustering K-Means sia sul dataset originale che su quello con i valori imputati. Traccia i punti dati raggruppati e calcola e traccia i centri dei cluster. Confronta i risultati del clustering con e senza dati mancanti per osservare gli effetti dell’imputazione dei dati. (10 punti)\n",
    "==============================================================================================================\n",
    "**Question2:** Consider the \"make_circles\" dataset from Sklearn. Perform K-Means clustering (K=2 clusters). To generate the dataset, use 300 samples, a factor of 0.5, and add noise with a parameter noise=0.1. Introduce random missing values to 10% of the dataset, then impute these missing values using the median imputation method. Perform K-Means clustering on both the original dataset and the dataset with imputed values. Plot the clustered data points and calculate and plot the cluster centers. Compare the clustering results with and without missing data to observe the effects of data imputation. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "\n",
    "# Generate make_circles dataset\n",
    "X, y = ?\n",
    "\n",
    "# Introduce random missing values (10% of the data)\n",
    "np.random.seed(42)\n",
    "missing_mask = ?\n",
    "X_missing = ?\n",
    "X_missing[missing_mask] = np.nan\n",
    "\n",
    "# Impute the missing values using the median imputation method\n",
    "imputer = ?\n",
    "X_imputed = ?\n",
    "\n",
    "\n",
    "# Perform K-Means clustering on the original dataset\n",
    "kmeans_original = ?\n",
    "kmeans_original.?\n",
    "centers_original = kmeans_original.?\n",
    "labels_original = kmeans_original.?\n",
    "\n",
    "# Perform K-Means clustering on the dataset with imputed values\n",
    "kmeans_imputed = ?\n",
    "kmeans_imputed.?\n",
    "centers_imputed = kmeans_imputed.?\n",
    "labels_imputed = kmeans_imputed.?\n",
    "\n",
    "# Plot the clustered data points and cluster centers for the original dataset\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(?, ?, c=labels_original, cmap='viridis', marker='o', edgecolor='k')\n",
    "plt.scatter(centers_original[?], centers_original[?], c='red', s=200, alpha=0.75, marker='X')\n",
    "plt.title('K-Means Clustering (Original Data)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# Plot the clustered data points and cluster centers for the imputed dataset\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(?, ?, c=labels_imputed, cmap='viridis', marker='o', edgecolor='k')\n",
    "plt.scatter(centers_imputed[?], centers_imputed[?], c='red', s=200, alpha=0.75, marker='X')\n",
    "plt.title('K-Means Clustering (Imputed Data)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Compare the clustering results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--2VVEeN5EFs"
   },
   "source": [
    "**Domanda3**: Considera il dataset \"iris\" di Sklearn. Determina il numero ottimale di cluster (K) utilizzando l'algoritmo di clustering K-Means. Imposta valori di K che vanno da 1 a 10, calcola la somma dei quadrati dei cluster (inertia o SSE) e il punteggio silhouette per ciascun K. Traccia i valori di inertia e i punteggi silhouette rispetto al numero di cluster (K) e identifica il valore di K ottimale basato sul punteggio silhouette e inertia. (10 punti)\n",
    "==============================================================================================================\n",
    "**Question3:** Consider the \"iris\" dataset from Sklearn. Determine the optimal number of clusters (K) using the K-Means clustering algorithm. Set K values ranging from 1 to 10, compute the cluster sum of squares (inertia) and the silhouette score for each K. Plot the inertia values and silhouette scores against the number of clusters (K), and identify the optimal K based on the silhouette score and inertia. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "p0sCfecT8CWk",
    "outputId": "d8cd9ba9-8f3e-47fc-8f27-481593691042"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "\n",
    "# Load the iris dataset and define data\n",
    "iris = ?\n",
    "X = ?\n",
    "\n",
    "# Range of K values to test\n",
    "K_range = ?\n",
    "inertia_values = []\n",
    "silhouette_scores = []\n",
    "\n",
    "# Compute inertia and silhouette score for each K\n",
    "?\n",
    "\n",
    "# Plot the inertia values against the number of clusters (K)\n",
    "?\n",
    "\n",
    "# Plot the silhouette scores against the number of clusters (K)\n",
    "?\n",
    "\n",
    "?\n",
    "\n",
    "# what is optimal K? \n",
    "optimal_K = ?\n",
    "print(f'The optimal K is: {optimal_K}')\n",
    "\n",
    "# explain why this k is chosen as the optimal (spiegare perché questo k è scelto come ottimale)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
